# ğŸ“š Transformer Modelleri ve LLMâ€™lere GiriÅŸ â€“ Ã–zet

### ğŸ§  DoÄŸal Dil Ä°ÅŸleme (NLP) ve LLMâ€™ler

- NLP, metin sÄ±nÄ±flandÄ±rmadan metin Ã¼retimine kadar birÃ§ok gÃ¶revi kapsar.
- LLMâ€™ler, bÃ¼yÃ¼k miktarda metin verisiyle eÄŸitilmiÅŸ, Ã§ok gÃ¼Ã§lÃ¼ dil modelleridir.
- Tek bir model, Ã§ok Ã§eÅŸitli gÃ¶revleri yerine getirebilir.
- Ancak bu modellerin **halÃ¼sinasyon Ã¼retme**, **Ã¶nyargÄ± taÅŸÄ±ma** gibi sÄ±nÄ±rlÄ±lÄ±klarÄ± da vardÄ±r.



### âš™ï¸ Transformer Yetenekleri

ğŸ¤— Transformers kÃ¼tÃ¼phanesindeki `pipeline()` fonksiyonu ile Ã¶nceden eÄŸitilmiÅŸ modelleri kolayca kullanabilirsin:

- Metin sÄ±nÄ±flandÄ±rma, varlÄ±k tanÄ±ma, soru-cevaplama
- Metin Ã¼retimi ve Ã¶zetleme
- Ã‡eviri ve diÄŸer diziden diziye gÃ¶revler
- Ses tanÄ±ma ve gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma



## ğŸ—ï¸ Transformer Mimarisi

Transformer modelinin temel Ã§alÄ±ÅŸma prensipleri:

- **Attention (dikkat)** mekanizmasÄ± modelin baÄŸlamÄ± anlamasÄ±nÄ± saÄŸlar.
- **Transfer learning** ile modeller, yeni gÃ¶revlerde yeniden kullanÄ±labilir.
- ÃœÃ§ ana mimari tÃ¼rÃ¼ vardÄ±r:
  - **Encoder-only** (sadece kodlayÄ±cÄ±)
  - **Decoder-only** (sadece Ã§Ã¶zÃ¼cÃ¼)
  - **Encoder-decoder** (hem kodlayÄ±cÄ± hem Ã§Ã¶zÃ¼cÃ¼)



## ğŸ§© Model Mimarileri ve KullanÄ±m AlanlarÄ±

| Mimari TÃ¼rÃ¼     | Ã–rnek Modeller                   | KullanÄ±m AlanlarÄ±                                       |
|------------------|-----------------------------------|----------------------------------------------------------|
| Encoder-only     | BERT, DistilBERT, ModernBERT      | CÃ¼mle sÄ±nÄ±flandÄ±rma, varlÄ±k tanÄ±ma, bilgi Ã§Ä±karÄ±mÄ±       |
| Decoder-only     | GPT, LLaMA, Gemma, SmolLM         | Metin Ã¼retimi, sohbet botlarÄ±, yaratÄ±cÄ± yazÄ±m            |
| Encoder-decoder  | BART, T5, Marian, mBART           | Ã–zetleme, Ã§eviri, Ã¼retici soru-cevap                     |



## ğŸš€ Modern LLM GeliÅŸmeleri

- Modeller zamanla hem boyut hem de yetenek aÃ§Ä±sÄ±ndan bÃ¼yÃ¼dÃ¼.
- **Scaling laws** (Ã¶lÃ§ekleme yasalarÄ±), modelin boyutuyla performansÄ± nasÄ±l artÄ±racaÄŸÄ±nÄ± Ã¶ngÃ¶rÃ¼r.
- Daha uzun baÄŸlamlarÄ± iÅŸlemek iÃ§in **Ã¶zel attention mekanizmalarÄ±** geliÅŸtirildi.
- EÄŸitim sÃ¼reci iki aÅŸamaya ayrÄ±lmÄ±ÅŸtÄ±r:
  - **Pretraining** (Ã¶n eÄŸitim)
  - **Instruction tuning** (talimatla ince ayar)



## ğŸ› ï¸ Pratik Uygulamalar

Bu bÃ¶lÃ¼mde Ã¶ÄŸrendiklerinle, modelleri gerÃ§ek dÃ¼nyada nasÄ±l kullanabileceÄŸini de gÃ¶rdÃ¼n:

- **Hugging Face Hub** Ã¼zerinden Ã¶nceden eÄŸitilmiÅŸ modelleri bulmak ve kullanmak
- **Inference API** ile modelleri doÄŸrudan tarayÄ±cÄ±da test etmek
- Hangi modelin hangi gÃ¶reve uygun olduÄŸunu anlamak



## ğŸ”­ GeleceÄŸe BakÄ±ÅŸ

ArtÄ±k Transformer modellerinin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na dair saÄŸlam bir temel oluÅŸturduÄŸuna gÃ¶re, sonraki bÃ¶lÃ¼mlerde ÅŸunlarÄ± Ã¶ÄŸreneceksin:

- Transformers kÃ¼tÃ¼phanesiyle modelleri nasÄ±l yÃ¼kleyip ince ayar yapacaÄŸÄ±n
- FarklÄ± veri tÃ¼rlerini modele nasÄ±l hazÄ±rlayacaÄŸÄ±n
- Ã–nceden eÄŸitilmiÅŸ modelleri kendi gÃ¶revlerine nasÄ±l uyarlayacaÄŸÄ±n
- Bu modelleri nasÄ±l daÄŸÄ±tacaÄŸÄ±n (deploy)
