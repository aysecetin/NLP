
# ğŸ”— Her Åeyi Bir Araya Getirmek

Her adÄ±mÄ± manuel yapmaya Ã§alÄ±ÅŸtÄ±k:
- Tokenizer nasÄ±l Ã§alÄ±ÅŸÄ±r?
- Tokenization, input ID'ye Ã§evirme
- Padding, truncation, attention mask

Ama aslÄ±nda ğŸ¤— Transformers API tÃ¼m bu iÅŸlemleri bizim yerimize **tek adÄ±mda** yapabiliyor.

## âš™ï¸ Basit KullanÄ±m

```python
from transformers import AutoTokenizer

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."
model_inputs = tokenizer(sequence)
```

Burada `model_inputs`, modele verilecek tÃ¼m bilgileri iÃ§erir:
- `input_ids`
- `attention_mask`
- (BazÄ± modellerde baÅŸka giriÅŸler de olabilir)



## ğŸ“¥ Birden Fazla CÃ¼mle ile KullanÄ±m

```python
sequences = [
    "I've been waiting for a HuggingFace course my whole life.",
    "So have I!"
]

model_inputs = tokenizer(sequences)
```



## ğŸ“ Otomatik Padding

### En uzun cÃ¼mleye gÃ¶re:
```python
tokenizer(sequences, padding="longest")
```

### Modele gÃ¶re:
```python
tokenizer(sequences, padding="max_length")
```

### Belirli uzunlukta:
```python
tokenizer(sequences, padding="max_length", max_length=8)
```



## âœ‚ï¸ Otomatik Truncation

### Modele gÃ¶re kÄ±salt:
```python
tokenizer(sequences, truncation=True)
```

### Belirli uzunlukta kÄ±salt:
```python
tokenizer(sequences, max_length=8, truncation=True)
```



## ğŸ”„ Tensor FormatÄ± SeÃ§mek

```python
# PyTorch tensÃ¶rleri
tokenizer(sequences, padding=True, return_tensors="pt")

# NumPy dizileri
tokenizer(sequences, padding=True, return_tensors="np")
```



## ğŸ”  Ã–zel Token'lar

Tokenizer bazen ek token ID'leri ekler:

```python
tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)

print(ids)
# [1045, 1005, 2310, ..., 2166, 1012]

model_inputs = tokenizer(sequence)
print(model_inputs["input_ids"])
# [101, 1045, 1005, ..., 2166, 1012, 102]
```

### Decode farkÄ±:

```python
tokenizer.decode(model_inputs["input_ids"])
# "[CLS] i've been waiting ... my whole life. [SEP]"

tokenizer.decode(ids)
# "i've been waiting ... my whole life."
```

`[CLS]` ve `[SEP]` gibi token'lar modelin eÄŸitildiÄŸi formatla uyumlu Ã§Ä±ktÄ±lar Ã¼retmek iÃ§in gereklidir. Tokenizer bunu senin yerinde otomatik yapar.



## âœ… BaÅŸtan Sona: Tokenizer'dan Modele

```python
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)

sequences = [
    "I've been waiting for a HuggingFace course my whole life.",
    "So have I!"
]

tokens = tokenizer(sequences, padding=True, truncation=True, return_tensors="pt")
output = model(**tokens)
```

Bu sayede:
- CÃ¼mle sayÄ±sÄ± fark etmez
- Uzunluk sÄ±nÄ±rÄ±na gÃ¶re otomatik kÄ±saltma olur
- Tensor formatÄ± ayarlanabilir
- Modele doÄŸrudan veri verilebilir



Bu yapÄ±, Hugging Face Transformers ile NLP iÅŸ akÄ±ÅŸlarÄ±nÄ± oldukÃ§a kolaylaÅŸtÄ±rÄ±r ğŸš€
