
# ğŸ”¤ Tokenizer Nedir ve NasÄ±l Ã‡alÄ±ÅŸÄ±r?

Transformer modelleri yalnÄ±zca **sayÄ±sal veriyle** Ã§alÄ±ÅŸabilir. Tokenizerâ€™lar, metni bu sayÄ±sal forma Ã§eviren araÃ§lardÄ±r.

---

## ğŸ“Œ Temel AmaÃ§

Ham metin:
```
Jim Henson was a puppeteer
```

Model bunu anlayamaz. Tokenizer bu metni anlamlÄ± ve minimum bilgi kaybÄ±yla **sayÄ±lara Ã§evirir**.

---

## ğŸ§± Tokenizer TÃ¼rleri

### 1. **Kelime TabanlÄ± (Word-based) Tokenizer**
```python
"Jim Henson was a puppeteer".split()
# ['Jim', 'Henson', 'was', 'a', 'puppeteer']
```

- Her kelimeye bir ID atanÄ±r.
- "dog" â‰  "dogs", "run" â‰  "running"
- Ã‡ok bÃ¼yÃ¼k vocabulary gerekir.
- Bilinmeyen kelimeler iÃ§in `[UNK]` tokenâ€™Ä± kullanÄ±lÄ±r.

---

### 2. **Karakter TabanlÄ± (Character-based) Tokenizer**

```text
"puppeteer" â†’ ['p', 'u', 'p', 'p', 'e', 't', 'e', 'e', 'r']
```

- KÃ¼Ã§Ã¼k vocabulary
- `[UNK]` yok denecek kadar az
- Ancak uzunluk artar ve her karakter anlamsÄ±zdÄ±r

---

### 3. **Alt-kelime TabanlÄ± (Subword-based) Tokenizer**

Ã–rnek:
- `"annoyingly"` â†’ `"annoying"` + `"ly"`
- `"tokenization"` â†’ `"token"` + `"ization"`

AvantajlarÄ±:
- AnlamlÄ± alt tokenâ€™lar
- KÃ¼Ã§Ã¼k vocabulary ile geniÅŸ kapsama
- TÃ¼rkÃ§e gibi eklemeli dillerde idealdir

---

### 4. **PopÃ¼ler YÃ¶ntemler**

- **BPE (Byte Pair Encoding)** â€“ GPT-2
- **WordPiece** â€“ BERT
- **SentencePiece / Unigram** â€“ Multilingual modeller

---

## ğŸ’¾ Tokenizer YÃ¼kleme ve Kaydetme

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
tokenizer.save_pretrained("klasor_adi")
```

---

## ğŸ” Encoding (Metni SayÄ±ya Ã‡evirme)

### 1. Tokenization
```python
tokens = tokenizer.tokenize("Using a Transformer network is simple")
# ['Using', 'a', 'transform', '##er', 'network', 'is', 'simple']
```

### 2. Token IDâ€™lerine DÃ¶nÃ¼ÅŸtÃ¼rme
```python
ids = tokenizer.convert_tokens_to_ids(tokens)
# [7993, 170, 11303, 1200, 2443, 1110, 3014]
```

---

## ğŸ” Decoding (SayÄ±lardan Metne Geri DÃ¶nÃ¼ÅŸ)

```python
decoded = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])
# 'Using a Transformer network is simple'
```

---

## ğŸ§ª Uygulama Ã–nerisi

Åu cÃ¼mleleri tokenize et ve IDâ€™lere Ã§evir:
- "I've been waiting for a HuggingFace course my whole life."
- "I hate this so much!"

SonuÃ§larÄ± Ã¶nceki Ã¶rneklerle karÅŸÄ±laÅŸtÄ±r.

---

## ğŸ”š Ã–zet

Tokenizerâ€™lar:
- Metni tokenâ€™lara bÃ¶ler,
- BunlarÄ± sayÄ±lara Ã§evirir,
- Gerekirse geri Ã§evirir,
- Modelin anlayabileceÄŸi formatÄ± oluÅŸturur.
