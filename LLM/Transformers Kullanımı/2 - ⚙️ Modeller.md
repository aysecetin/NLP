# ğŸš€ Transformer Modeli OluÅŸturma ve Kullanma (Hugging Face Transformers)

### 1. AutoModel ile Model YÃ¼kleme


```python
from transformers import AutoModel
model = AutoModel.from_pretrained("bert-base-cased")
```

- from_pretrained() metodu modeli Hugging Face Hub Ã¼zerinden indirir ve Ã¶nbelleÄŸe alÄ±r.

- bert-base-cased: 12 katmanlÄ±, 768 boyutlu gizli vektÃ¶r, 12 attention head iÃ§eren, bÃ¼yÃ¼k-kÃ¼Ã§Ã¼k harf ayrÄ±mÄ± yapan bir BERT modelidir.

- AutoModel: Hangi model tÃ¼rÃ¼ olduÄŸunu otomatik belirler ve uygun sÄ±nÄ±fÄ± yÃ¼kler.

- Alternatif olarak, doÄŸrudan modeli de Ã§aÄŸÄ±rabilirsin:

```python
from transformers import BertModel
model = BertModel.from_pretrained("bert-base-cased")
```
### 2. Modeli Kaydetme ve YÃ¼kleme
```python
model.save_pretrained("klasor_adi")
```

Bu klasÃ¶re iki dosya kaydedilir:

- config.json: Model mimarisi ve metadata bilgisi.

- pytorch_model.bin: Modelin aÄŸÄ±rlÄ±klarÄ± (state dict).

Tekrar yÃ¼klemek iÃ§in:

```python
model = AutoModel.from_pretrained("klasor_adi")
```

### 3. Modeli Hugging Face Hubâ€™a YÃ¼kleme
GiriÅŸ yap:

```python
from huggingface_hub import notebook_login
notebook_login()
```
ya da terminalden:

```bash
huggingface-cli login
```

Modeli yÃ¼kle:


```python
model.push_to_hub("benim-harika-modelim")
```

DiÄŸer kullanÄ±cÄ±lar da artÄ±k ÅŸu ÅŸekilde modeli kullanabilir:


```python
model = AutoModel.from_pretrained("kullaniciadi/benim-harika-modelim")
```


### âœï¸ **Metni SayÄ±lara Ã‡evirme (`Tokenizer`)**

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")

encoded = tokenizer("Merhaba, bu bir cÃ¼mledir!")
print(encoded)
```

Bu iÅŸlem 3 ÅŸey dÃ¶ner:

- `input_ids`: Kelimelerin sayÄ±sal karÅŸÄ±lÄ±klarÄ±  
- `token_type_ids`: Hangi kelime hangi cÃ¼mleye ait (Ã§ift cÃ¼mlelerde iÅŸe yarar)  
- `attention_mask`: Hangi tokenâ€™lara dikkat edilsin (Ã¶rneÄŸin padding olanlara edilmez)  

Geri Ã§evirmek iÃ§in:

```python
tokenizer.decode(encoded["input_ids"])
```

Ã–rnek Ã§Ä±ktÄ±:  
`[CLS] Merhaba, bu bir cÃ¼mledir! [SEP]`

---

### ğŸ§± **Ã‡oklu CÃ¼mleleri Ä°ÅŸlemek**

```python
encoded = tokenizer(
    ["NasÄ±lsÄ±n?", "Ä°yiyim, teÅŸekkÃ¼rler!"],
    return_tensors="pt",
    padding=True
)
```

- FarklÄ± uzunluktaki cÃ¼mleleri eÅŸit boyuta getirmek iÃ§in `padding=True` kullanÄ±lÄ±r.  
- `return_tensors="pt"` ile PyTorch tensÃ¶rleri dÃ¶ner.  
- `truncation=True` ile Ã§ok uzun cÃ¼mleler kesilir.  

---

### ğŸ”  **Ã–zel Tokenlar (Special Tokens)**

- BERT gibi modeller `[CLS]` ve `[SEP]` gibi Ã¶zel token'lara ihtiyaÃ§ duyar.  
- Tokenizer bu tokenâ€™larÄ± otomatik olarak ekler.  

---

### ğŸ§ª **Modeli Ã‡alÄ±ÅŸtÄ±rmak**

```python
import torch

inputs = tokenizer("Bir Ã¶rnek cÃ¼mle", return_tensors="pt")
outputs = model(**inputs)
```

- Tokenizer Ã§Ä±ktÄ±sÄ± doÄŸrudan modelin iÃ§ine verilebilir.  

---

### ğŸ’¡ Neden Bu Kadar UÄŸraÅŸÄ±yoruz?

Ã‡Ã¼nkÃ¼:

- Transformer modelleri metinle deÄŸil sayÄ±larla Ã§alÄ±ÅŸÄ±r.  
- SayÄ±lar modelin anlayabileceÄŸi ÅŸekilde hazÄ±rlanmalÄ± (tokenize edilmeli, pad/truncate edilmeli, maskâ€™lenmeli).  
- Her modelin beklentisi farklÄ± olabilir (Ã¶rneÄŸin Ã¶zel tokenlar).  

